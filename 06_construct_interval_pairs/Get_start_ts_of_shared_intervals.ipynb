{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import datetime as dt\n",
    "import json\n",
    "import operator\n",
    "import os\n",
    "\n",
    "import iso8601\n",
    "import pandas as pd\n",
    "\n",
    "import bb_binary.parsing as bbb_p\n",
    "import bb_videos_archiv.core as bb_va"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def toggle(param):\n",
    "    if param == 'left':\n",
    "        return 'right'\n",
    "    elif param == 'right':\n",
    "        return 'left'\n",
    "    elif param ==  0:\n",
    "        return 1\n",
    "    elif param == 1:\n",
    "        return 0\n",
    "    elif param == 2:\n",
    "        return 3\n",
    "    elif param == 3:\n",
    "        return 2\n",
    "    else:\n",
    "        raise ValueError(\"Just the following values are accepted 'left', 'right', 0, 1, 2 and 3.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_n_parse_json(path):\n",
    "    df = pd.read_json(path)\n",
    "    df['cam_id'] = df.apply(lambda row: bbb_p.parse_video_fname(row['start_video_name'])[0], axis=1)\n",
    "    df['ts_start'] = df.apply(lambda row: bbb_p.parse_video_fname(row['start_video_name'])[1], axis=1)\n",
    "    df['ts_end'] = df.apply(lambda row: bbb_p.parse_video_fname(row['end_video_name'])[2], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sorted_intervals(path_left, path_right):\n",
    "    \"\"\"Return dataframe, wich contains the intervals from `path_left` and `path_right` sorted by their timesamp\n",
    "    of the starting frame.\n",
    "    \n",
    "    Args:\n",
    "        path_left (str): path of the json file, which holds the intervals from step 5 of cam 5.\n",
    "        path_right (str): path of the json file, which holds the intervals from step 5 of cam 5.\n",
    "        cam_id_left (str): id of the left camera.\n",
    "        cam_id_right (str): id of the right camera.     \n",
    "    \"\"\"\n",
    "    data_cam_l = read_n_parse_json(path_left)\n",
    "    data_cam_r = read_n_parse_json(path_right)\n",
    "    intervals = pd.concat([data_cam_l, data_cam_r], axis=0, ignore_index=True)\n",
    "    return intervals.sort_values(by='ts_start', ascending=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_intersection_interval(sorted_data, cam_id_left, cam_id_right, thold):\n",
    "    # Diese Funktion ist dafür um festzustellen welche Zeitintervalle als potentiell der gleiche Anfang angesehen\n",
    "    # werden können.\n",
    "    concat = False\n",
    "    shared_intervals = []\n",
    "    memory = None\n",
    "    id_sh = 0\n",
    "    for i, (idx_i, row_older) in enumerate(sorted_data.iterrows()):\n",
    "\n",
    "        # Intervall besteht aus start und entpunkt, als gesamte Zeitangabe und dann jeweils die entsprechendenden Videos\n",
    "        # für jede Kamera\n",
    "        shared_interval = {}\n",
    "        export_keys = ['stable', 'id', 'info', 'start_video_name', 'ts_start', 'cam_id']\n",
    "        \n",
    "        side = 'left' if row_older['cam_id'] == cam_id_left else 'right'\n",
    "\n",
    "        shared_interval[side] = {}\n",
    "        for key in export_keys:\n",
    "            shared_interval[side][key] = row_older[key]\n",
    "        shared_interval[toggle(side)] = memory\n",
    "\n",
    "        if memory is not None:\n",
    "            memory = None\n",
    "            shared_interval['id'] = id_sh\n",
    "            id_sh += 1\n",
    "            shared_intervals.append(shared_interval)\n",
    "            continue\n",
    "\n",
    "        row_younger = sorted_data.iloc[i+1]\n",
    "\n",
    "        if row_younger['cam_id'] == row_older['cam_id']: \n",
    "            shared_interval['id'] = id_sh\n",
    "            id_sh += 1\n",
    "            shared_intervals.append(shared_interval)\n",
    "        else:\n",
    "            if (row_older['ts_start'] - row_younger['ts_start']) < thold:\n",
    "                memory = {}\n",
    "                for key in export_keys:\n",
    "                    memory[key] = row_older[key]\n",
    "            else:\n",
    "                shared_interval['id'] = id_sh\n",
    "                id_sh += 1\n",
    "                shared_intervals.append(shared_interval)\n",
    "    return shared_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_video_names_sorted(path):\n",
    "    \"\"\"Dies gibt ein dict zurück, welches als keys 'Cam_0' bis 'Cam_3' enthält.\n",
    "    \n",
    "    Unter jedem key ist eine geordnete liste aller filenames enthalten.\n",
    "    \"\"\"\n",
    "    video_files = {}\n",
    "    for __,__,files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith('.mkv'):\n",
    "                cam_id, __, __ = bbb_p.parse_video_fname(file)\n",
    "\n",
    "                cam_id_str = 'Cam_{id}'.format(id=cam_id)\n",
    "                if cam_id_str not in video_files:\n",
    "                    video_files[cam_id_str] = []\n",
    "\n",
    "                video_files[cam_id_str].append(file)\n",
    "\n",
    "    for key in video_files.keys():\n",
    "        video_files[key].sort()\n",
    "    return video_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_closest_video(ts, sorted_video_files, th):\n",
    "    \"\"\"Bestimmt das nächstliegende video, mittels th kann ein Schwellwert abgegeben werden,\n",
    "    sodas falls der timtestamp 'ts' am ende eines Videos liegt. Das Nachfolgende Video ausgegeben werden.\n",
    "    \"\"\"\n",
    "    time_delta = dt.timedelta(seconds=th)\n",
    "    for i, video in enumerate(sorted_video_files):\n",
    "        __, ts_start, ts_end = bbb_p.parse_video_fname(video)\n",
    "        if ts_start < ts:\n",
    "            if ts < ts_end:\n",
    "                if ts_end - ts < time_delta and (i < len(sorted_video_files) -1):\n",
    "                    return sorted_video_files[i+1]\n",
    "                else:\n",
    "                    return video\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            return video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extend_closest_videos(intervals, year, root_dir):\n",
    "    \"\"\"Sollte für ein Interval einer Kamera kein korrespondierendes Video der anderen Kamera existieren,\n",
    "    wird hier nach dem nächstliegenden gesucht.\n",
    "    \"\"\"\n",
    "    # va = bb_va.Video_Archiv(year, root_dir)\n",
    "    video_files = get_all_video_names_sorted(root_dir)\n",
    "    # intervals = copy.deepcopy(intervals_org)\n",
    "    for i, interval in enumerate(intervals):\n",
    "        for key in ['left', 'right']:\n",
    "            if interval[key] is None:\n",
    "                exist_key = toggle(key)\n",
    "                non_exist_cam = toggle(interval[exist_key]['cam_id'])\n",
    "                ts = interval[exist_key]['ts_start']\n",
    "                ts = ts.strftime('%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "                ts = iso8601.parse_date(ts)\n",
    "                cam_id_str = 'Cam_{id}'.format(id=non_exist_cam)\n",
    "                video = get_closest_video(ts, video_files[cam_id_str], 5)\n",
    "                \n",
    "                __, ts_start_video, __= bbb_p.parse_fname(video)\n",
    "                time_delta = dt.timedelta(minutes=30)\n",
    "                \n",
    "                if (abs(ts_start_video-ts) < time_delta):\n",
    "                    interval[key] = {}\n",
    "                    interval[key]['start_video_name'] = video\n",
    "                    interval[key]['stable'] = intervals[i-1][key]['stable']\n",
    "                    interval[key]['cam_id'], interval[key]['ts_start']= bbb_p.parse_video_fname(video)[:2]\n",
    "                    interval[key]['info'] = 'closest video'\n",
    "    return intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_2_valid_json(shared_intervals):\n",
    "    shared_intervals_valid_json = []\n",
    "    for interval in shared_intervals:\n",
    "        valid_interval = copy.deepcopy(interval)\n",
    "        valid_interval['id'] = len(shared_intervals) - valid_interval['id'] - 1\n",
    "        for key in ['left', 'right']:\n",
    "            if valid_interval[key] is not None:\n",
    "                for key_ts in ['ts_start', 'ts_end']:\n",
    "                    if key_ts in interval[key]:\n",
    "                        valid_interval[key][key_ts] = interval[key][key_ts].strftime('%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "\n",
    "        for key_ts in ['ts_start', 'ts_end']:\n",
    "            if key_ts in interval:\n",
    "                valid_interval[key_ts] = interval[key_ts].strftime('%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "        shared_intervals_valid_json.append(valid_interval)\n",
    "    return shared_intervals_valid_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_valid_intersection_intervals(path_left, path_right, cam_left, cam_right, thold, year, root_dir):\n",
    "    sorted_data = get_sorted_intervals(path_left, path_right)\n",
    "    shared_intervals = get_intersection_interval(sorted_data, cam_left, cam_right, thold)\n",
    "    extended_shared_intervals = extend_closest_videos(shared_intervals, year, root_dir)\n",
    "    return extended_shared_intervals[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_2_doc_n_locally(json_data, doc_path, filename):\n",
    "    with open(filename, 'w') as fp:\n",
    "        json.dump(json_data, fp, sort_keys=True, indent=2)\n",
    "    \n",
    "    with open(os.path.join(doc_path, filename), 'w') as fp:\n",
    "        json.dump(json_data, fp, sort_keys=True, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thold = dt.timedelta(seconds=90)\n",
    "doc_path = '../docs'\n",
    "root_dir = './videos_proxy'\n",
    "year = '2016'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_left = '05c_Cam_0_intervals_ecc_stable_join_man.json'\n",
    "path_right = '05c_Cam_1_intervals_ecc_stable_join_man.json'\n",
    "\n",
    "cam_left = 0\n",
    "cam_right = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shared_intervals_valid_json_01 = get_valid_intersection_intervals(path_left, path_right, cam_left, cam_right, thold, year, root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_left = '05c_Cam_2_intervals_ecc_stable_join_man.json'\n",
    "path_right = '05c_Cam_3_intervals_ecc_stable_join_man.json'\n",
    "filename = '06_Cam_23_intervals_pair.json'\n",
    "cam_left = 2\n",
    "cam_right = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shared_intervals_valid_json_23 = get_valid_intersection_intervals(path_left, path_right, cam_left, cam_right, thold, year, root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_files = get_all_video_names_sorted(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervalle = []\n",
    "for i in range(4):\n",
    "    path = '05c_Cam_{cam_id}_intervals_ecc_stable_join_man.json'.format(cam_id=i)\n",
    "    data = read_n_parse_json(path)\n",
    "    intervalle.append(data)\n",
    "df = pd.concat(intervalle, axis=0, ignore_index=True)\n",
    "df = df.sort_values(by='ts_start', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stable_info(df, cam_id, ts_start, ts_end):\n",
    "    result = df[((df.cam_id ==cam_id) & (df.ts_start <= ts_start) & (ts_end <= df.ts_end))]\n",
    "    if len(result) == 1:\n",
    "        return bool(result['stable'].values[0])\n",
    "    else:\n",
    "        print(ts_start)\n",
    "        print(ts_end)\n",
    "        print(cam_id)\n",
    "        return True\n",
    "        raise Exception('Es gibt mehr als ein Interval in dem dieses \"beschnitte\" Interval liegt, das sollte nicht möglich sein!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extend_end_video_name(intervals, videos_files):\n",
    "    \"\"\"Bestimmt in Abhängigkeit zur Kamera das letzte Video eines Intervals.\"\"\"\n",
    "    for idx, interval in enumerate(intervals):\n",
    "        for key in ['left', 'right']:\n",
    "            \n",
    "            if interval[key] is not None:\n",
    "                cam_id_str = 'Cam_{id}'.format(id=interval[key]['cam_id'])\n",
    "                curr_idx = idx + 1\n",
    "                # falls das folgende Interval leer ist \n",
    "                while curr_idx  < len(intervals) and intervals[curr_idx][key] is None:\n",
    "                    curr_idx = curr_idx + 1\n",
    "\n",
    "                if curr_idx  < len(intervals) and intervals[curr_idx][key] is not None:\n",
    "                    next_start_video = intervals[curr_idx][key]['start_video_name']\n",
    "                    next_idx = video_files[cam_id_str].index(next_start_video)\n",
    "                    end_idx = next_idx - 1\n",
    "                    interval[key]['end_video_name'] = video_files[cam_id_str][end_idx]\n",
    "                    __, __, interval[key]['ts_end'] = bbb_p.parse_video_fname(interval[key]['end_video_name'])\n",
    "                    interval[key]['stable'] = get_stable_info(df, interval[key]['cam_id'],interval[key]['ts_start'], interval[key]['ts_end'])\n",
    "                if curr_idx == len(intervals):\n",
    "                    interval[key]['end_video_name'] = video_files[cam_id_str][-1]\n",
    "                    __, __, interval[key]['ts_end'] = bbb_p.parse_video_fname(interval[key]['end_video_name'])\n",
    "                    interval[key]['stable'] = get_stable_info(df, interval[key]['cam_id'],interval[key]['ts_start'], interval[key]['ts_end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extend_end_video_name(shared_intervals_valid_json_01, video_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extend_end_video_name(shared_intervals_valid_json_23, video_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extend_overall_interval(intervals):\n",
    "    \"\"\"Bestimmt Anfangs und Endzeitpunkt des gemeinsamen Intervals und markiert ein gemeinsames\n",
    "    Interval als stable, wenn beide Videos stable sind.\"\"\"\n",
    "    def _set_interval_key(interval, key, relate):\n",
    "        if interval['left'] is not None and interval['right'] is not None:\n",
    "            if relate(interval['left'][key], interval['right'][key]):\n",
    "                interval[key] = interval['left'][key]\n",
    "            else:\n",
    "                interval[key] = interval['right'][key]\n",
    "        else:\n",
    "            if interval['left'] is None:\n",
    "                interval[key] = interval['right'][key]\n",
    "            else:\n",
    "                interval[key] = interval['left'][key]\n",
    "\n",
    "    for i, interval in enumerate(intervals):\n",
    "        _set_interval_key(interval, 'ts_start', operator.lt)\n",
    "        _set_interval_key(interval, 'ts_end', operator.gt)\n",
    "        if interval['left'] is None:\n",
    "            interval['stable'] = interval['right']['stable']\n",
    "        elif interval['right'] is None:\n",
    "            interval['stable'] = interval['left']['stable']\n",
    "        else:\n",
    "            interval['stable'] = interval['left']['stable'] and interval['right']['stable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = '06_Cam_01_intervals_pair.json'\n",
    "converted_01 = convert_2_valid_json(shared_intervals_valid_json_01)\n",
    "extend_overall_interval(converted_01)\n",
    "save_2_doc_n_locally(converted_01, doc_path, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filename = '06_Cam_23_intervals_pair.json'\n",
    "converted_23 = convert_2_valid_json(shared_intervals_valid_json_23)\n",
    "extend_overall_interval(converted_23)\n",
    "save_2_doc_n_locally(converted_23, doc_path, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
